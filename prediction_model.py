# -*- coding: utf-8 -*-
"""CruzHacks.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wYAFiZXRq9WeHy-vUpG1JQ05VVDzaZ1A
"""

import pandas as pd
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer
from sklearn import metrics
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import PassiveAggressiveClassifier
import numpy as np
from sklearn.externals import joblib
import matplotlib.pyplot as plt
import itertools
import re
import nltk

true = pd.read_csv("True.csv")

true.head(3)

fake = pd.read_csv("Fake.csv")

fake.head(3)

fake.shape

true.shape

true['fact'] = 1

fake['fact'] = 0

fake.head(3)

true.head(3)

dataTotal = [true.loc[0:5000][:], fake.loc[0:5000][:]]

totalData = pd.concat(dataTotal)

totalData.shape

totalData.sample(frac=1).reset_index(drop=True)

xAxis = totalData.drop("fact",axis=1)

yAxis = totalData['fact']

totalData = totalData.dropna()

stringTotal = totalData.copy()

stringTotal.reset_index(inplace = True)

stringTotal.head()

stringTotal['text'][34]

stringTotal['fact'][34]

"""# **Natural Language Processing**
This step makes program more efficient and lessens the contrains on the machine learning aspect of the program
"""



singleStem = PorterStemmer()

nltk.download('stopwords')
limit = []
for i in range(0,len(stringTotal)):
  review = re.sub('[^a-zA-Z]', ' ', stringTotal['text'][i])
  review = review.lower()
  review = review.split()
  review = [singleStem.stem(word) for word in review if not word in stopwords.words('english')]
  review = ' '.join(review)
  limit.append(review)

vector = TfidfVectorizer(max_features=5000, ngram_range=(1,3))

vector.get_params()

xAxis = vector.fit_transform(limit).toarray()

yAxis = stringTotal['fact']

X_train, X_test, y_train, y_test = train_test_split(xAxis, yAxis, test_size=0.2, random_state=0)

data_count = pd.DataFrame(X_train, columns=vector.get_feature_names())

data_count.head(3)

identifier = PassiveAggressiveClassifier(max_iter=1000)

identifier.fit(X_train, y_train)

predictor = identifier.predict(X_test)
accuracy = metrics.accuracy_score(y_test,predictor)

print(accuracy)

review = re.sub('[^a-zA-Z]', ' ', true['text'][16888])
review = review.lower()
review = review.split()
review = [singleStem.stem(word) for word in review if not word in stopwords.words('english')]
review = ' '.join(review)

inputData = vector.transform([review]).toarray()

pd.DataFrame(inputData, columns = vector.get_feature_names())

identifier.predict(inputData)

joblib.dump(identifier, 'model.pkl')

joblib.dump(vector, 'tfidfvect.pkl')
